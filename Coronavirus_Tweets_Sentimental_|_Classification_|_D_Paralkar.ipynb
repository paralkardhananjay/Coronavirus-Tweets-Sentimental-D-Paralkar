{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "PBTbrJXOngz2",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "578E2V7j08f6",
        "67NQN5KX2AMe",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "bmKjuQ-FpsJ3",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paralkardhananjay/Coronavirus-Tweets-Sentimental-D-Paralkar/blob/main/Coronavirus_Tweets_Sentimental_%7C_Classification_%7C_D_Paralkar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Coronavirus Tweets Sentiment Analysis-Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** - Dhananjay Paralkar\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "The COVID-19 pandemic has had a profound impact on society, with lockdown measures severely restricting people's movement and affecting their daily lives. To better understand how people are feeling during this time, we analyzed tweets on Twitter. As a popular social media platform, Twitter is an important means of expression, allowing users to share their thoughts, experiences, and feelings.\n",
        "By examining a large number of tweets, we learned how people are coping with the challenges posed by the pandemic. We looked for patterns and trends in the language used, the topics discussed, and the overall emotion conveyed in these tweets. This analysis allows us to deepen our understanding of collective sentiment, highlighting both the hardships and resilience of individuals during these difficult times.\n",
        "In addition, by reviewing the views expressed on Twitter, we sought to identify emerging needs, concerns, or areas of support. This information can be useful to policymakers, organizations and communities to effectively respond to the ongoing pandemic and take steps to address the specific challenges facing individuals. face.\n",
        "Taken together, our analysis of Twitter tweets during the COVID-19 pandemic provides valuable insights into people's feelings, experiences, and needs, shedding light on the multifaceted impact of crisis for the whole society."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WDevelop a model to analyze the sentiment of tweets about the coronavirus. The dataset contains labeled tweets categorized as positive, negative, or neutral. The goal is to train a model that accurately classifies the sentiment of COVID-19 tweets. This will help understand public emotions, track sentiment changes, and provide insights for researchers, policymakers, and organizations. The model can be used to monitor real-time sentiment, inform communication strategies, and address concerns related to the pandemic.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "nltk.download('all',quiet=True)\n",
        "from PIL import Image\n",
        "\n",
        "#Model libraries\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_GNX5CuSVBTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "Twitter = pd.read_csv('/content/drive/MyDrive/Coronavirus_Tweets.csv', encoding='latin-1')\n",
        "# tweet =pd.read_csv(database)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "Twitter"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter.head()\n"
      ],
      "metadata": {
        "id": "lvCokqVEi_6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "Twitter.shape\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter.columns,Twitter.index\n",
        "\n"
      ],
      "metadata": {
        "id": "ApppRn_XjFKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Twitter.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "Twitter.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "Twitter.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "missing_values = Twitter.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=missing_values.index, y=missing_values)\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Missing Values')\n",
        "plt.title('Missing Values in the Twitter Column')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In the given dataset, the \"Location\" column contains 8590 duplicate values. Processing duplicates in the \"Location\" column is an important step in the data preprocessing phase of a classification machine learning project.\n",
        "One approach is to remove duplicate values ​​from the \"Location\" column. This ensures that each unique position is represented only once in the data set, reducing redundancy and potentially improving data quality.\n",
        "Another approach is to resolve duplicates through further analysis. Understanding the reasoning behind duplicates can help determine the appropriate course of action. If there are valid reasons for duplicate entries, such as multiple entries for the same location due to different sources or format variations, you can choose to keep them and manage them accordingly.*"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "Twitter.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "Twitter.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = Twitter.apply(lambda col: col.unique())\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter.Sentiment.unique()\n"
      ],
      "metadata": {
        "id": "GecEonr3lBw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter.Location.unique()\n"
      ],
      "metadata": {
        "id": "jgfeXhHslDPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Count the number of occurrences of each sentiment value in the 'Sentiment' column of the 'Twitter' DataFrame and reset the index\n",
        "sentiment_count = Twitter['Sentiment'].value_counts().reset_index()\n",
        "# Rename the columns of the resulting DataFrame to 'Sentiment' and 'count', respectively\n",
        "sentiment_count.columns = ['Sentiment','count']\n",
        "sentiment_count"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the piechart for Sentiments distribution\n",
        "plt.figure(figsize=(18,7))\n",
        "ax = sns.barplot(x=\"Sentiment\", y='count', data=sentiment_count)\n",
        "ax.set_title(\"Proportion of Sentiment\", fontsize=20)\n",
        "ax.set_xlabel(\"Sentiment\", fontsize=20)\n",
        "ax.set_ylabel('count', fontsize=20)"
      ],
      "metadata": {
        "id": "iSlTy_9ClJS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing values\n",
        "replace_values = {\"Sentiment\":{'Extremely Negative':'Negative', 'Extremely Positive':'Positive'}}\n",
        "tweet = Twitter.replace(replace_values)\n",
        "\n",
        "\n",
        "sentiment_count1 = tweet['Sentiment'].value_counts().reset_index()\n",
        "sentiment_count1.columns = ['Sentiment','count']\n",
        "sentiment_count1"
      ],
      "metadata": {
        "id": "GDKK-XwqlL-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "bar chart is an effective visual representation to show the count of tweets for each sentiment category. Each sentiment category can be represented by a separate bar, and the height of each bar corresponds to the count of tweets for that specific sentiment category. This allows for a clear and concise visualization of the distribution of sentiment categories in the dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart demonstrates that the count of tweets with a positive sentiment is higher compared to the count of tweets with negative or neutral sentiments."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Plotting the piechart for Sentiments distribution\n",
        "sentiment_count1 = tweet['Sentiment'].value_counts().to_list()\n",
        "labels=['Positive','Negative','Netural']\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.pie(x=sentiment_count1,explode=[0.04,0.04,0.1],shadow= True,labels=labels,autopct=\"%.2f%%\",radius=1.1)\n",
        "plt.title(\"Proportion Of Sentiments\", fontsize=20)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, a pie chart is an effective way to visually represent the relative proportions of different sentiment categories (positive, negative, and neutral) within the entire set of tweets. It provides a quick and easy comparison between these categories, highlighting their respective sizes."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive sentiment constitutes the highest proportion, accounting for 43.85% of the total, followed by negative sentiment at 37.41%. The remaining 19% is attributed to the neutral sentiment category."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#calculates the length (number of characters) of each tweet and stores the result in the text_length column.\n",
        "tweet['text_length'] = tweet['OriginalTweet'].apply(len)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_character_length=tweet['text_length'].sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "IBMoJ3RgmLKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame `top_tweet_character_length` from `tweet_character_length\n",
        "top_tweet_character_length=pd.DataFrame(tweet_character_length)\n",
        "# Reset the index of `top_tweet_character_length` and assign the result back to `top_tweet_character_length`\n",
        "top_tweet_character_length.reset_index(inplace=True)\n",
        "# Rename the columns of `top_tweet_character_length` to 'Original_Tweet_Row' and 'tweet_character_Count'\n",
        "top_tweet_character_length.rename(columns={'index':'Original_Tweet_Row', 'text_length':'tweet_character_Count'}, inplace=True)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "PdOgy-sWmMtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_tweet_character_length\n"
      ],
      "metadata": {
        "id": "D24nSz9ymObI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top 10 tweets with the longest character lengths, sort them in descending order, and assign them to `top_tweet_length`\n",
        "top_tweet_length=top_tweet_character_length.head(10).sort_values(by='tweet_character_Count',ascending=False)\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Create a bar plot using Seaborn, with 'Original_Tweet_Row' on the x-axis, 'tweet_character_Count' on the y-axis, and `top_tweet_length` as the data source\n",
        "bar_plot = sns.barplot(x=\"Original_Tweet_Row\", y=\"tweet_character_Count\", data=top_tweet_length, palette='viridis')\n",
        ""
      ],
      "metadata": {
        "id": "W26NIBj1mhGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the data, a bar chart is a good choice. Each location can be represented by a bar, with the height of the bar indicating the tweet character count."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Row 25160 has the longest tweet with 350 characters.\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Top 10 most frequently occurring locations from the 'Location' column of the tweet DataFrame.\n",
        "Top_Location_Of_tweet= tweet['Location'].value_counts().head(10)\n",
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns.set_style('white')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top_Location_Of_tweet\n"
      ],
      "metadata": {
        "id": "QCt0Iry4nSYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top_Location_Of_tweet=pd.DataFrame(Top_Location_Of_tweet)\n",
        "Top_Location_Of_tweet.reset_index(inplace=True)\n",
        "Top_Location_Of_tweet.rename(columns={'index':'Location', 'Location':'Location_Count'}, inplace=True)\n",
        "Top_Location_Of_tweet"
      ],
      "metadata": {
        "id": "S6hizMYMnT7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a bar plot using Seaborn library\n",
        "viz_1=sns.barplot(x=\"Location\", y=\"Location_Count\", data=Top_Location_Of_tweet,\n",
        "                 palette=\"husl\")\n",
        "# Set plot title, y-axis label, and x-axis label\n",
        "viz_1.set_title('Locations with most of the tweets')\n",
        "viz_1.set_ylabel('Count of listings')\n",
        "viz_1.set_xlabel('Location Names')\n",
        "# Rotate x-axis labels by 45 degrees to make them easier to read\n",
        "viz_1.set_xticklabels(viz_1.get_xticklabels(), rotation=45)"
      ],
      "metadata": {
        "id": "rqF6QBBDnVPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is a concise and effective way to visualize the distribution of tweet counts across different locations. The chart shows the count of tweets from each location as a bar, with the bar height reflecting the tweet count. This visualization makes it easy to see which locations have the most tweets and which locations have the least tweets."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "London City has Highest tweet comapred to other city tweet.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Count the number of tweets for each unique date in the 'TweetAt' column of `tweet` and display the 15 most frequent dates\n",
        "tweet['TweetAt'].value_counts()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of tweets for each unique date in the 'TweetAt' column of `tweet` and display the 15 most frequent dates\n",
        "tweet['TweetAt'].value_counts().head(15)"
      ],
      "metadata": {
        "id": "4blvLq53neI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "# plot the original tweet column as a bar plot\n",
        "tweet['TweetAt'].value_counts().head(15).plot(kind='bar',color='green')\n",
        "\n",
        "# set the plot title and axis labels\n",
        "plt.title('Count of Original Tweets by Date')\n",
        "plt.xlabel('Tweet Date')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "w__O3utSnfne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot is a common and widely used chart type for visualizing categorical data, such as dates or categories, with a discrete count or frequency associated with each category."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a date 20 March 2020 has highest number of tweet Around 3450\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "correlation_matrix = Twitter.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Map for Coronavirus Tweets')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " It is a good way to visualize the correlation between different variables. The heatmap shows the correlation between each pair of variables as a color, with warmer colors indicating a stronger correlation and cooler colors indicating a weaker correlation."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap uses color to represent the correlation between variables. Darker colors indicate a stronger correlation, while lighter colors indicate a weaker correlation or no correlation. Positive correlation means that as one variable increases, the other variable also increases. Negative correlation means that as one variable increases, the other variable decreases."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "tweet.isnull().sum().sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "print(tweet[['OriginalTweet', 'Sentiment']].info())"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        ""
      ],
      "metadata": {
        "id": "1YHAsz8D8ptj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "7VdMck8y8rDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n"
      ],
      "metadata": {
        "id": "5raWNAbJ8sTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# Remove Punctuations\n",
        "# Remove URLs & Remove words and digits contain digits\n",
        "# Remove Stopwords\n",
        "# Remove White spaces\n",
        "# Rephrase Text\n",
        "# Tokenization\n",
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "def transform_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove non-alphanumeric characters\n",
        "    words = [word for word in words if word.isalnum()]\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    punctuation_set = set(string.punctuation)\n",
        "    words = [word for word in words if word not in stopwords_set and word not in punctuation_set]\n",
        "\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # Join words into a string and return\n",
        "    return ' '.join(lemmatized_words)"
      ],
      "metadata": {
        "id": "pJFlRjih8wui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this context, we exclusively employ the technique of Lemmatization for text normalization. Lemmatization involves reducing words to their base or dictionary form, which is referred to as a lemma. By utilizing Lemmatization, we ensure that the text is presented in a standardized form, which can then be used for classification modeling purposes"
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_text(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today https/20.89.\")\n"
      ],
      "metadata": {
        "id": "I4G56pNk9I4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply the `transform_text()` function to each value in the 'OriginalTweet' column of `tweet`\n",
        "tweet[\"Clean_Tweets\"] = tweet['OriginalTweet'].apply(transform_text)"
      ],
      "metadata": {
        "id": "mUIs8iqt9KZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the 'OriginalTweet' value in the row with integer in `tweet`\n",
        "Twitter.iloc[25160][\"OriginalTweet\"]"
      ],
      "metadata": {
        "id": "-oZoWMtW9L5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Twitter.head()"
      ],
      "metadata": {
        "id": "lfRphif19NnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a new column in `tweet` called 'temp_list'\n",
        "tweet['temp_list'] = tweet['Clean_Tweets'].apply(lambda x:str(x).split())"
      ],
      "metadata": {
        "id": "5ZZijxsW9PFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet['temp_list']"
      ],
      "metadata": {
        "id": "BWEXCO6B9QpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# Create a flattened list of all words in the nested list column\n",
        "word_list = [word for sublist in tweet['temp_list'] for word in sublist]\n",
        "\n",
        "# Count the frequency of each word and store in a Counter object\n",
        "word_counts = Counter(word_list)\n",
        "\n",
        "# Create a dataframe of the top 30 most common words\n",
        "top_words = pd.DataFrame(word_counts.most_common(30), columns=['Common_words', 'count'])\n",
        "\n",
        "# Apply a background gradient to the dataframe for better visualization\n",
        "styled_top_words = top_words.style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "id": "1z__-lKZ9SgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_words"
      ],
      "metadata": {
        "id": "xCzK9qdA9UVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame called `neutral` containing only the 'Clean_Tweets' column from `tweet` where the 'Sentiment' column is 'Neutral','positive','negative'.\n",
        "neutral=pd.DataFrame(tweet[['Clean_Tweets']] [tweet['Sentiment'] == 'Neutral'])\n",
        "positive=pd.DataFrame(tweet[['Clean_Tweets']] [tweet['Sentiment'] == 'Positive'])\n",
        "negative=pd.DataFrame(tweet[['Clean_Tweets']] [tweet['Sentiment'] == 'Negative'])\n",
        ""
      ],
      "metadata": {
        "id": "AKyc1-yp9WQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive.head()"
      ],
      "metadata": {
        "id": "ZIqQLD5w9Y6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative.head()"
      ],
      "metadata": {
        "id": "CBoBkqbI9bdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wordcloud"
      ],
      "metadata": {
        "id": "UcpJwhDJ9f_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list called `spam_corpus`\n",
        "spam_corpus = []\n",
        "# Iterate over each row in a DataFrame called `tweet` where the 'Sentiment' column has the value 'Neutral'\n",
        "for msg in tweet[tweet['Sentiment'] =='Neutral']['Clean_Tweets'].tolist():\n",
        "  # Split the 'Clean_Tweets' value into individual words using the `split()` method\n",
        "    for word in msg.split():\n",
        "       # Append each word to the `spam_corpus` list\n",
        "        spam_corpus.append(word)"
      ],
      "metadata": {
        "id": "F4vqBiZJ9hha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_words\n"
      ],
      "metadata": {
        "id": "W0PTbmCa9itq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the `Counter` class from the `collections` module\n",
        "from collections import Counter\n",
        "plt.figure(figsize=(20,10))\n",
        "# Import the `seaborn` library for creating data visualizations\n",
        "sns.barplot(x='Common_words',y='count',data=top_words)\n",
        "# Set the x-axis labels to be vertical\n",
        "plt.xticks(rotation='vertical')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EayF21La9kJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the `WordCloud` class from the `wordcloud` module\n",
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(width=500,height=500,min_font_size=10,background_color='white')\n",
        "\n"
      ],
      "metadata": {
        "id": "2PvGRes39mOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a WordCloud object\n",
        "wc = WordCloud()\n",
        "\n",
        "# Generate the word cloud using the 'Clean_Tweets' column\n",
        "tweet_wc = wc.generate(str(neutral['Clean_Tweets']))\n",
        "\n",
        "# Create a new figure with a custom size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Display the word cloud\n",
        "plt.imshow(tweet_wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D_A0FaQo9zYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a WordCloud object\n",
        "wc = WordCloud()\n",
        "\n",
        "# Generate the word cloud using the 'Clean_Tweets' column\n",
        "tweet_wc = wc.generate(str(positive['Clean_Tweets']))\n",
        "\n",
        "# Create a new figure with a custom size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Display the word cloud\n",
        "plt.imshow(tweet_wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mLj7PTK5-Ctd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning dependent and independent features\n",
        "X= tweet['Clean_Tweets']\n",
        "y=tweet['Sentiment']"
      ],
      "metadata": {
        "id": "9FLjcfMG_iK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Train test split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=10)\n",
        ""
      ],
      "metadata": {
        "id": "J23IoOce_kIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By allocating 80% of the data for training and 20% for testing, we provide a larger portion of the dataset for the training process. This decision allows the model to learn more intricate patterns and trends within the data. Consequently, the model becomes more capable of making accurate predictions on new or unseen data. The increased training data enables the model to capture a broader representation of the underlying patterns and improve its ability to generalize to unseen instances."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking shape of splitted data\n",
        "print(X_train.shape)\n",
        "y_test.shape\n",
        ""
      ],
      "metadata": {
        "id": "CCgEzlPp_tQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Information about dataset\n",
        "Twitter.info()"
      ],
      "metadata": {
        "id": "do29Jhfy_7Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our machine learning modeling, we have chosen to utilize only two columns: 'Original Tweet' and 'Sentiment'. We have ensured that both columns have an equal number of rows. By focusing on these two columns, we can extract meaningful information from the text data in 'Original Tweet' and associate it with the corresponding sentiment in the 'Sentiment' column. This approach allows us to train our model specifically on the text content and its associated sentiment, enabling us to make predictions and classifications based on these features."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count Of vectorization with bag of words model"
      ],
      "metadata": {
        "id": "Xxls7u4OA2ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count vectorization is a process of converting a piece of text into a numerical format that can be used by machine learning algorithms. In this process, the text is first split into words or tokens, and then each token is counted to create a vector of numbers representing the frequency of each word in the text."
      ],
      "metadata": {
        "id": "EUS-NPynBCUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "metadata": {
        "id": "uP-olXAMA2Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words\n",
        "bw=CountVectorizer(binary=False,max_df=1.0,min_df=5,ngram_range=(1,2))\n",
        "bw_X_train=bw.fit_transform(X_train.astype(str).str.strip())"
      ],
      "metadata": {
        "id": "ob-7FP-dBGzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the NumPy array bw_X_train\n",
        "bw_X_train.shape\n",
        ""
      ],
      "metadata": {
        "id": "RpjokuANBH9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Trained CountVectorizer 'bw' to transform the test data 'X_test' into a bag-of-words representation\n",
        "# The text data in 'X_test' is first converted to a string representation & then stripped of leading & trailing whitespace characters\n",
        "bw_X_test=bw.transform(X_test.astype(str).str.strip())"
      ],
      "metadata": {
        "id": "Wv8t3_BlBJKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the NumPy array bw_X_test\n",
        "bw_X_test.shape\n",
        ""
      ],
      "metadata": {
        "id": "KHI7JgXWBKor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Logistic Regression*"
      ],
      "metadata": {
        "id": "BpppHqDcAdJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a statistical model used to estimate the probability of an event occurring. It calculates the odds of the event's outcome falling within the range of 0 to 1. In the case of multiclass classification, Logistic Regression determines the probability distribution across multiple classes by utilizing a linear combination of one or more independent variables. By analyzing the relationship between these variables and the event's outcome, Logistic Regression allows us to make predictions and understand the likelihood of different outcomes in a classification problem."
      ],
      "metadata": {
        "id": "IBhTeqKHAs5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the logistic regression model\n",
        "lr_cv = LogisticRegression()\n",
        "\n",
        "# Defining a dictionary of hyperparameters to tune over\n",
        "parameters = {\n",
        "    'penalty': ['l1', 'l2'],  # Regularization penalty to apply (L1 or L2)\n",
        "    'C': [100, 10, 1.0, 0.1, 0.01]  # Inverse of regularization strength (lower values indicate stronger regularization)\n",
        "}\n",
        "\n",
        "# Creating a GridSearchCV object with cross-validation of 15\n",
        "logreg_Gcv = GridSearchCV(lr_cv, parameters, cv=15)\n",
        "\n",
        "# Fitting the training data to the GridSearchCV object to find the best hyperparameters\n",
        "logreg_Gcv.fit(bw_X_train, y_train)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_lr_cv = logreg_Gcv.predict(bw_X_test)"
      ],
      "metadata": {
        "id": "vWb-Rg4zBQpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr_cv"
      ],
      "metadata": {
        "id": "mG0bJt88BSJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "accuracy_lr_cv = accuracy_score(y_test,pred_lr_cv)\n",
        "print(\"Accuracy :\",(accuracy_lr_cv))"
      ],
      "metadata": {
        "id": "SfPHoVwPBTnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['neutral','positive','negative']\n",
        "print(classification_report(y_test,pred_lr_cv))\n",
        ""
      ],
      "metadata": {
        "id": "KQ97IDoaBVHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Confussion matrix\n",
        "\n",
        "cf1 = confusion_matrix(y_test, pred_lr_cv)\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cf1, annot=True, fmt=\".0f\", ax=ax, cmap=\"Blues\")  # Set the desired color map (e.g., \"Blues\")\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (Logistic Regression with CV)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CgHduEKDBfiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm utilized in this case is Logistic Regression, which achieved an accuracy of 79%. Various evaluation metrics, such as precision, recall, and F1 score, were computed for each label, namely 'Negative', 'Neutral', and 'Positive'. The scores for these metrics have shown improvement compared to previous results. This indicates that the Logistic Regression model has become more effective in correctly classifying instances for each sentiment category. The increased precision, recall, and F1 score reflect the model's enhanced ability to accurately identify and classify instances into their respective sentiment labels."
      ],
      "metadata": {
        "id": "h-jiKjOBBxEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this scenario, GridSearchCV is employed to fine-tune the hyperparameters of the logistic regression model. Specifically, two hyperparameters are tuned: the regularization penalty, which can be either L1 or L2, and the inverse of the regularization strength, denoted as C. The model's performance is evaluated using cross-validation, with the number of folds set to 15 (cv=15). By systematically exploring different combinations of hyperparameter values, GridSearchCV identifies the optimal configuration that maximizes the model's performance. This approach helps in selecting the most effective regularization penalty and regularization strength for the logistic regression model, resulting in improved overall performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, as seen in above Evaluation metric Score Chart as follows\n",
        "\n",
        "Accuracy:-79%\n",
        "\n",
        "precision:-77%\n",
        "\n",
        "recall:- 77%\n",
        "\n",
        "f1-score:- 77%"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier with CV"
      ],
      "metadata": {
        "id": "g1qIJJkwCSzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a graphical representation that resembles a flowchart. It consists of internal nodes, branches, and leaf nodes. Each internal node represents a test performed on a specific attribute or feature. The outcome of the test determines the path the decision tree follows down the branches. Each branch represents one of the possible outcomes of the test, leading to subsequent nodes or leaves. Leaf nodes, also known as terminal nodes, represent the final prediction or decision, which could be a class label or a numerical value in the case of regression. Decision Trees are commonly used in machine learning for both classification and regression tasks due to their interpretability and ability to capture complex decision-making processes."
      ],
      "metadata": {
        "id": "0rdpmMaECacV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "dt_cv=DecisionTreeClassifier()\n",
        "\n",
        "#fitting the data to model\n",
        "dt_cv.fit(bw_X_train,y_train)\n",
        "\n",
        "#predicted values\n",
        "pred_dt_cv=dt_cv.predict(bw_X_test)\n",
        ""
      ],
      "metadata": {
        "id": "ME6oqEtwCdUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "cv_score_dt_cv= cross_val_score(dt_cv,bw_X_train,y_train, cv=5)\n",
        "print(\"Accuracy: {}\" .format(np.mean(cv_score_dt_cv)))"
      ],
      "metadata": {
        "id": "et34vuE2Ceq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_dt_cv))"
      ],
      "metadata": {
        "id": "KbDTHzerCgY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf2= (confusion_matrix(y_test,pred_dt_cv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf2, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (Decision tree with CV)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "TLc28mRWCiDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree algorithm was utilized in this scenario and achieved an accuracy of 70%. Evaluation metrics such as precision, recall, and F1 score were computed for the labels 'Negative', 'Neutral', and 'Positive'. The model's performance improved across these metrics, indicating its enhanced ability to correctly classify instances into their respective sentiment categories."
      ],
      "metadata": {
        "id": "QCJGpmroCstV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn library is used to perform cross-validation on the decision tree model with 5 folds. The np.mean function is then used to calculate the average accuracy score across all folds"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, as seen in above Evaluation metric Score Chart as follows\n",
        "\n",
        "Accuracy:-70%\n",
        "\n",
        "precision:-71%\n",
        "\n",
        "recall:- 70%\n",
        "\n",
        "f1-score:- 71%"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN(K-Nearest Neighbours)"
      ],
      "metadata": {
        "id": "lLaG3qCyDWGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a simple algorithm that works by finding the K closest instances in the training data to a given input instance and then assigning the label of the majority class among those instances as the predicted label for the input instance."
      ],
      "metadata": {
        "id": "zLScA4UtDbsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define parameter grid with range of values for n_neighbors\n",
        "param_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,9]}\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Fit KNN model to training data and perform grid search\n",
        "grid_search.fit(bw_X_train, y_train)\n",
        "\n",
        "# Print best hyperparameters and corresponding mean cross-validation score\n",
        "print('Best hyperparameters:', grid_search.best_params_)\n",
        "print('Mean cross-validation score:', grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "Vt08R8kADZFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_knn_cv = grid_search.predict(bw_X_test)"
      ],
      "metadata": {
        "id": "foyNRDSmDgnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_knn_cv\n"
      ],
      "metadata": {
        "id": "NdgofXe6Dh1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_KNN = accuracy_score(y_test,pred_knn_cv)\n",
        "print(\"Accuracy :\",(accuracy_KNN))\n",
        ""
      ],
      "metadata": {
        "id": "uMNYhBS0DjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_knn_cv))"
      ],
      "metadata": {
        "id": "wwPbCPP3DlK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_knn = confusion_matrix(y_test, pred_knn_cv)\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cf_knn, annot=True, fmt=\".0f\", ax=ax, cmap=\"Greens\")  # Set the desired color map (e.g., \"Greens\")\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (KNN with CV)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GZE642IsDrqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN algorithm was used to classify the data, resulting in an accuracy of 39%. Additionally, different evaluation metrics, such as precision, recall, and f1 score, were calculated for each label ('Negative', 'Neutral', 'Positive') and showed not improved compared to the baseline model"
      ],
      "metadata": {
        "id": "VS13JsbmD78f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The range of possible values for n_neighbors is defined in the param_grid dictionary, which contains a list of integers from 1 to 9. GridSearchCV is then used to evaluate the performance of the KNN algorithm with each value of n_neighbors, using 5-fold cross-validation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, as seen in above Evaluation metric Score Chart as follows\n",
        "\n",
        "Accuracy:-38%\n",
        "\n",
        "Precision:-53%\n",
        "\n",
        "Recall:-47%\n",
        "\n",
        "f1-score:- 40%"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "pUKscANkEgpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest is an ensemble learning algorithm that constructs multiple decision trees on randomly sampled subsets of the training data. Each tree is trained on different subsets of features and data to reduce overfitting and enhance generalization performance. During prediction, the input instance is evaluated by each tree, and the final prediction is determined by majority voting among the individual tree predictions. This ensemble approach improves accuracy and robustness by leveraging the collective wisdom of multiple decision trees."
      ],
      "metadata": {
        "id": "6_sTIJ0-Eq6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "rf_clf =RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit classifier to training data\n",
        "rf_clf.fit(bw_X_train, y_train)\n",
        "\n",
        "# Predict labels for test data\n",
        "y_pred_rf = rf_clf.predict(bw_X_test)\n",
        "\n",
        "# Calculate accuracy of classifier on test data\n",
        "accuracy_rf = (y_pred_rf == y_test).mean()\n",
        "print('Accuracy_rf:', accuracy_rf)"
      ],
      "metadata": {
        "id": "A_jnRPtbEtlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,y_pred_rf))"
      ],
      "metadata": {
        "id": "DoHI9q7ZEvH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf7 = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cf7, annot=True, fmt=\".0f\", ax=ax, cmap=\"YlGnBu\")  # Set the desired color map (e.g., \"YlGnBu\")\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (Random Forest with CV)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xgqLjzWBE6LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.**"
      ],
      "metadata": {
        "id": "XM3I3RexFCGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest algorithm was used to classify the data, resulting in an accuracy of 76%. Additionally, different evaluation metrics, such as precision, recall, and f1 score, were calculated for each label ('Negative', 'Neutral', 'Positive') and not slightly improved compared to the baseline model."
      ],
      "metadata": {
        "id": "4uKqEi91FEdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Which hyperparameter optimization technique have you used and why?**"
      ],
      "metadata": {
        "id": "P09-2UGRFGvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Classifier utilized a hyperparameter optimization technique. The classifier was instantiated with default hyperparameter values of n_estimators=100 and random_state=42 in the absence of explicit hyperparameter tuning."
      ],
      "metadata": {
        "id": "iHT1q3rEFVi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart\n",
        "\n",
        "**"
      ],
      "metadata": {
        "id": "FT8XP6TVFXXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, as seen in above Evaluation metric Score Chart as follows\n",
        "\n",
        "Accuracy:-76%\n",
        "\n",
        "Precision:-75%\n",
        "\n",
        "Recall:- 75%\n",
        "\n",
        "f1-score:-75%"
      ],
      "metadata": {
        "id": "B_Kcq__vFaew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Models by TF/IDF Vectorizer"
      ],
      "metadata": {
        "id": "CZwACExfG5D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=tweet['Clean_Tweets']\n",
        "y=tweet['Sentiment']"
      ],
      "metadata": {
        "id": "Ek0CKHS0HSNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Train test split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=10)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "y_test.shape"
      ],
      "metadata": {
        "id": "X0gEDSdrHZgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization Text\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "\n",
        "# TF-IDF\n",
        "tv=TfidfVectorizer(use_idf=True,max_df=1.0,min_df=5,ngram_range=(1,2),sublinear_tf=True)\n",
        "tv_X_train=tv.fit_transform(X_train.astype(str).str.strip())\n",
        "\n",
        "\n",
        "tv_X_train.shape\n",
        ""
      ],
      "metadata": {
        "id": "ncBr0Mn2HYET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_X_test=tv.transform(X_test.astype(str).str.strip())\n"
      ],
      "metadata": {
        "id": "fXBavAAnH8Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "OxPrGkm7HCaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "lr_tv=LogisticRegression()\n",
        "parameters = dict(penalty=['l1', 'l2'],C=[100, 10, 1.0, 0.1, 0.01])\n",
        "\n",
        "#Hyperparameter tuning by GridserchCV\n",
        "lr_tv_Gcv=GridSearchCV(lr_tv,parameters,cv=5)\n",
        "\n",
        "#fitting the data to model\n",
        "lr_tv_Gcv.fit(tv_X_train,y_train)"
      ],
      "metadata": {
        "id": "K4LpgOO1HH3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_lr_tv_Gcv = lr_tv_Gcv.predict(tv_X_test)"
      ],
      "metadata": {
        "id": "p6e_LS_dHJcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "accuracy_lr_Gcv = accuracy_score(y_test,pred_lr_tv_Gcv)\n",
        "print(\"Accuracy :\",(accuracy_lr_Gcv))\n",
        ""
      ],
      "metadata": {
        "id": "tUjvNsbhIBQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_lr_tv_Gcv))"
      ],
      "metadata": {
        "id": "7txTFN7FICtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf1a = confusion_matrix(y_test, pred_lr_tv_Gcv)\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cf1a, annot=True, fmt=\".0f\", ax=ax, cmap=\"PuBuGn\")  # Set the desired color map (e.g., \"PuBuGn\")\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (Logistic Regression with TF/IDF)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oBXwOgdoIKWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Explain the ML Model used and it's performance using Evaluation metric Score Chart.**\n",
        "****\n",
        "Answer Here.\n",
        "\n",
        "Logistic Regression algorithm was used to classify the data, resulting in an accuracy of 78%. Additionally, different evaluation metrics, such as precision, recall, and f1 score, were calculated for each label ('Negative', 'Neutral', 'Positive') and much improved compared to the all the baseline model.\n",
        "\n"
      ],
      "metadata": {
        "id": "8z1WBrmaISQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. **Which hyperparameter optimization technique have you used and why?**\n",
        "\n",
        "Answer Here.\n",
        "\n",
        "The hyperparameter space is defined by the \"parameters\" dictionary, which specifies the values of the regularization parameter C and the penalty term (l1 or l2). GridSearchCV also helps to prevent overfitting and ensures that the model generalizes well to unseen data.\n",
        "\n"
      ],
      "metadata": {
        "id": "b9doEBkSImTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart**\n",
        "\n",
        "Answer Here.\n",
        "\n",
        "Yes, as seen in above Evaluation metric Score Chart as follows and here accuracy is much better as compared to all the baseline model algorthim.This Logistic Regression algorthim used for model deployement as Sentiment Analysis using Vectorization techinque TF-IDF( Term Frequency -Inverse Document Frequency).\n",
        "\n",
        "Accuracy:-78%\n",
        "\n",
        "Precision:-79%\n",
        "\n",
        "Recall:- 79%\n",
        "\n",
        "f1-score:-79%"
      ],
      "metadata": {
        "id": "YovqmIMbIqTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "LAHUcqDUI2ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "dt_tv=DecisionTreeClassifier()\n",
        "\n",
        "#fitting the data to model\n",
        "dt_tv.fit(tv_X_train,y_train)\n",
        "\n",
        "#prediction\n",
        "pred_dt_tv=dt_tv.predict(tv_X_test)"
      ],
      "metadata": {
        "id": "MZu7ho_tI5fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dt_tv\n",
        ""
      ],
      "metadata": {
        "id": "R5kolfvTI69U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "cv_score_dt_tv= cross_val_score(dt_tv,tv_X_train,y_train, cv=5)\n",
        "print(\"Accuracy: {}\" .format(np.mean(cv_score_dt_tv)))"
      ],
      "metadata": {
        "id": "UhSS4oVJI8EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_dt_tv))"
      ],
      "metadata": {
        "id": "sx3fz0IiI9zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf2a = confusion_matrix(y_test, pred_dt_tv)\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cf2a, annot=True, fmt=\".0f\", ax=ax, cmap=\"YlOrBr\")  # Set the desired color map (e.g., \"YlOrBr\")\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (Decision Tree with TF/IDF)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mJV5XjzyJEVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:\n",
        "Observation:\n",
        "The model achieved an accuracy score of 60%, indicating that it is performing reasonably well.**"
      ],
      "metadata": {
        "id": "7l96mlTVJX0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN TF/ID"
      ],
      "metadata": {
        "id": "rgjAZVQMJngL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "knn = KNeighborsClassifier()\n",
        "param = {'n_neighbors': [1,2,3,4,5,6,7,8]}\n",
        "knn_tv = GridSearchCV(estimator=knn,param_grid=param)\n",
        "\n",
        "#fitting the data to model\n",
        "knn_tv.fit(tv_X_train, y_train)"
      ],
      "metadata": {
        "id": "3pUU_MYtJqKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_knn_tv = knn_tv.predict(tv_X_test)"
      ],
      "metadata": {
        "id": "QkOmMdk_Jr0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_knn_tv"
      ],
      "metadata": {
        "id": "iY0d0cQzJs4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_KNN_tv = accuracy_score(y_test,pred_knn_tv)\n",
        "print(\"Accuracy :\",(accuracy_KNN_tv))"
      ],
      "metadata": {
        "id": "Fc4HqQvPJuK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_knn_tv))"
      ],
      "metadata": {
        "id": "FCoeYhpVJvTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Confussion matrix\n",
        "cf4a= (confusion_matrix(y_test,pred_knn_tv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf4a, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "ax.set_ylabel('Actual labels', fontsize=15)\n",
        "ax.set_title('Confusion Matrix (KNN TF/IDF with GridsearchCV)', fontsize=20)\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "Qux_DlUoJxl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "The model achieved an accuracy score of 37%, which indicates that it is underperforming. A low accuracy score suggests that the model is not accurately predicting the target variable and may require further improvements or adjustments."
      ],
      "metadata": {
        "id": "Kv2QKm1JKEXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We utilized four different machine learning models: Logistic Regression, Decision Tree Classifier, KNN, and Random Forest. These models were applied to both Count Vector and TF-IDF Vectorization techniques.\n",
        "2. Based on our analysis, we determined that the Logistic Regression model  generated the best results. The model achieved an accuracy score of 78.28% for Count Vectorization and 77.43% for TF-IDF Vectorization. Following Logistic Regression, the SVM model also performed well.\n",
        "3. Our observations indicate that there is no overfitting in the data, suggesting that the models have not excessively fit the training data and can generalize well to unseen data. This implies that we can confidently deploy the chosen model.\n",
        "4. With this model in place, we can easily predict the sentiment of future tweets. The trained model can effectively classify new tweets into their corresponding sentiment categories"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}